{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_from_ipynb(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        notebook_data = json.load(f)\n",
    "\n",
    "    code_cells = [\n",
    "        ''.join(cell['source'])  \n",
    "        for cell in notebook_data['cells']\n",
    "        if cell['cell_type'] == 'code' \n",
    "    ]\n",
    "\n",
    "    return code_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'MemoRes.ipynb'  \n",
    "codes = extract_code_from_ipynb(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code cell 1:\n",
      "%pip install torch transformers\n",
      "%pip install ipywidgets\n",
      "%pip install -U \"huggingface_hub[cli]\"\n",
      "----------------------------------------\n",
      "Code cell 2:\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from transformers import AutoTokenizer, AdamW\n",
      "from transformers import AutoModelForCausalLM\n",
      "from huggingface_hub import notebook_login\n",
      "from torch.utils.data import DataLoader, Dataset\n",
      "from tqdm import tqdm\n",
      "import re\n",
      "----------------------------------------\n",
      "Code cell 3:\n",
      "MODEL_NAME = \"distilgpt2\"  \n",
      "LEARNING_RATE = 1e-4\n",
      "EPOCHS = 20\n",
      "BATCH_SIZE = 6\n",
      "MAX_LEN = 50\n",
      "FILE_NAME = 'model'\n",
      "----------------------------------------\n",
      "Code cell 4:\n",
      "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=\"\")\n",
      "tokenizer.pad_token = tokenizer.eos_token  \n",
      "----------------------------------------\n",
      "Code cell 5:\n",
      "class TextDataset(Dataset):\n",
      "    def __init__(self, texts, tokenizer, max_len=MAX_LEN):\n",
      "        self.texts = texts\n",
      "        self.tokenizer = tokenizer\n",
      "        self.max_len = max_len\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.texts)\n",
      "\n",
      "    def __getitem__(self, idx):\n",
      "        encodings = self.tokenizer(\n",
      "            self.texts[idx], truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\"\n",
      "        )\n",
      "        input_ids = encodings[\"input_ids\"].squeeze()\n",
      "        attention_mask = encodings[\"attention_mask\"].squeeze()\n",
      "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": input_ids}\n",
      "----------------------------------------\n",
      "Code cell 6:\n",
      "data = open('data/goida.txt').read() + open('data/doc77.txt').read()\n",
      "texts = re.split(r'[.!?]', data)\n",
      "texts = [t.strip() for t in texts if t]\n",
      "----------------------------------------\n",
      "Code cell 7:\n",
      "dataset = TextDataset(texts, tokenizer)\n",
      "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
      "----------------------------------------\n",
      "Code cell 8:\n",
      "class SimpleTransformerModel(nn.Module):\n",
      "    def __init__(self, model_name):\n",
      "        super(SimpleTransformerModel, self).__init__()\n",
      "        self.transformer = AutoModelForCausalLM.from_pretrained(model_name)\n",
      "\n",
      "    def forward(self, input_ids, attention_mask, labels=None):\n",
      "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
      "        loss = outputs.loss if labels is not None else None\n",
      "        logits = outputs.logits\n",
      "        return loss, logits\n",
      "----------------------------------------\n",
      "Code cell 9:\n",
      "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
      "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
      "----------------------------------------\n",
      "Code cell 10:\n",
      "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "model.to(device)\n",
      "----------------------------------------\n",
      "Code cell 11:\n",
      "def train_model(model, dataloader, optimizer, epochs=EPOCHS):\n",
      "    model.train()\n",
      "    total_steps = len(dataloader) * epochs \n",
      "    progress_bar = tqdm(total=total_steps, desc=\"Training Progress\")\n",
      "\n",
      "    for epoch in range(1, epochs + 1):\n",
      "        progress_bar.set_description(f\"Training Progress \")\n",
      "\n",
      "        for batch in dataloader:\n",
      "            input_ids = batch[\"input_ids\"].to(device)\n",
      "            attention_mask = batch[\"attention_mask\"].to(device)\n",
      "            labels = batch[\"labels\"].to(device)\n",
      "\n",
      "            optimizer.zero_grad()\n",
      "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
      "            loss = outputs.loss  \n",
      "\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "\n",
      "            progress_bar.update(1)\n",
      "            progress_bar.set_postfix(loss=loss.item(), epoch=epoch)\n",
      "\n",
      "    progress_bar.close()\n",
      "----------------------------------------\n",
      "Code cell 12:\n",
      "train_model(model, dataloader, optimizer)\n",
      "----------------------------------------\n",
      "Code cell 13:\n",
      "def generate_text(model, tokenizer, prompt, max_len=MAX_LEN, temperature=0.7, top_k=50, top_p=0.9):\n",
      "    model.eval()\n",
      "    input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True).input_ids\n",
      "\n",
      "    attention_mask = input_ids != tokenizer.pad_token_id\n",
      "\n",
      "    outputs = model.generate(\n",
      "        input_ids,\n",
      "        attention_mask=attention_mask,\n",
      "        max_length=max_len,\n",
      "        temperature=temperature,\n",
      "        top_k=top_k,\n",
      "        top_p=top_p,\n",
      "        num_return_sequences=1,\n",
      "        do_sample=True,\n",
      "        pad_token_id=tokenizer.pad_token_id,  \n",
      "        use_cache=False\n",
      "    )\n",
      "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
      "    return generated_text\n",
      "\n",
      "----------------------------------------\n",
      "Code cell 14:\n",
      "prompt = \"Итак, \"\n",
      "for _ in range(5): print(generate_text(model, tokenizer, prompt, temperature=0.1, max_len=1000))\n",
      "----------------------------------------\n",
      "Code cell 15:\n",
      "torch.save(model.state_dict(), f'models/{FILE_NAME}.pth')\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, code in enumerate(codes, 1):\n",
    "    print(f\"Code cell {i}:\\n{code}\\n{'-'*40}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
